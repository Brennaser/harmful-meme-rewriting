{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d689b6",
   "metadata": {},
   "source": [
    "# Gemma 2 plus BLIP Meme Rewriter\n",
    "\n",
    "This notebook walks through the **Gemma 2 + BLIP** pipeline step by step.\n",
    "\n",
    "Goal:  \n",
    "Take a meme image and its original text, then:\n",
    "\n",
    "1. Use **BLIP** to generate a short description of the image.  \n",
    "2. Combine that description with the original meme text in a prompt.  \n",
    "3. Call **Gemma 2** (text only model) to rewrite the meme text so it is non offensive but keeps the original meaning as much as possible.  \n",
    "4. Run this over a CSV file of memes.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- You have a GPU machine or Colab is okay.  \n",
    "- You have a Hugging Face account and an access token with permission to use Gemma 2.  \n",
    "- You have a CSV file `memes.csv` with columns: `id`, `image_path`, `text`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebbfe7",
   "metadata": {},
   "source": [
    "## 1. Install libraries\n",
    "\n",
    "Run this cell once to install required packages. You can skip if already installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d610f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.0' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# If you are in Colab, uncomment the next line\n",
    "# !pip install -q transformers huggingface_hub accelerate safetensors pillow torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117aacfd",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import (\n",
    "    BlipProcessor,\n",
    "    BlipForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76f993",
   "metadata": {},
   "source": [
    "## 3. Device setup and Hugging Face login\n",
    "\n",
    "You need a Hugging Face token with access to Gemma 2.\n",
    "\n",
    "You can either:\n",
    "\n",
    "- Set `HUGGINGFACE_TOKEN` as an environment variable, or  \n",
    "- Pass the token directly into `login()` in this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device (GPU if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Hugging Face login\n",
    "# Option 1: read from environment variable\n",
    "hf_token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Option 2: uncomment and paste directly (not recommended in shared notebooks)\n",
    "# hf_token = \"hf_...\"\n",
    "\n",
    "if not hf_token:\n",
    "    print(\"WARNING: No HUGGINGFACE_TOKEN found. Set it in the environment or here.\")\n",
    "else:\n",
    "    login(hf_token)\n",
    "    print(\"Logged into Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04b68f",
   "metadata": {},
   "source": [
    "## 4. Define the shared system prompt\n",
    "\n",
    "This is the same prompt we use across models. It explains the rewriting task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"You are a content safety editor for internet memes.\\n\"\n",
    "    \"Your job is to rewrite short meme text so that it is safe and non offensive \"\n",
    "    \"while keeping the original meaning, target, and joke structure as much as possible.\\n\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"1. Remove or soften slurs, insults, and explicit hate toward any group or person.\\n\"\n",
    "    \"2. Keep the same basic situation, characters, and point of view.\\n\"\n",
    "    \"3. Keep the text short, punchy, and meme like.\\n\"\n",
    "    \"4. Do not add new events or new facts. Small filler words are fine.\\n\"\n",
    "    \"5. If the input text is already safe and non offensive, return it unchanged.\\n\"\n",
    "    \"6. Reply with the rewritten meme text only.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833ecc0",
   "metadata": {},
   "source": [
    "## 5. Load BLIP image captioning model\n",
    "\n",
    "BLIP will turn each meme image into a short text description that we feed into Gemma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading BLIP captioning model...\")\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip-image-captioning-base\"\n",
    ").to(device)\n",
    "\n",
    "print(\"BLIP loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9318e",
   "metadata": {},
   "source": [
    "### Helper: caption one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_image(image_path: str) -> str:\n",
    "    \"\"\"Generate a short caption for the image using BLIP.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = blip_model.generate(**inputs, max_new_tokens=40)\n",
    "    caption = blip_processor.decode(out[0], skip_special_tokens=True).strip()\n",
    "    return caption\n",
    "\n",
    "# Example (update path to a real file before running)\n",
    "# test_caption = caption_image(\"img/example.png\")\n",
    "# print(\"BLIP caption:\", test_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62eeb4",
   "metadata": {},
   "source": [
    "## 6. Load Gemma 2 model\n",
    "\n",
    "We use the instruction tuned Gemma 2 model (`google/gemma-2-2b-it`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d239b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_model_id = \"google/gemma-2-2b-it\"\n",
    "\n",
    "print(\"Loading Gemma 2 model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(gemma_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    gemma_model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    ").to(device)\n",
    "\n",
    "print(\"Gemma 2 loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7a3d9",
   "metadata": {},
   "source": [
    "## 7. Function to rewrite a single meme\n",
    "\n",
    "This function:\n",
    "\n",
    "1. Captions the image with BLIP.  \n",
    "2. Builds a prompt combining the system prompt, image description, and original text.  \n",
    "3. Calls Gemma 2 to generate a safer rewrite.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_meme_with_gemma(image_path: str, original_text: str) -> str:\n",
    "    # 1) Caption image\n",
    "    caption = caption_image(image_path)\n",
    "\n",
    "    # 2) Build full prompt\n",
    "    prompt = (\n",
    "        f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "        f\"Image description: {caption}\\n\"\n",
    "        f\"Original meme text: {original_text}\\n\\n\"\n",
    "        \"Task:\\nRewrite this text so that it is safe and non offensive, \"\n",
    "        \"but still funny and as close as possible to the original meaning.\\n\"\n",
    "    )\n",
    "\n",
    "    # 3) Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "    full_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # Try to remove the prompt from the front and keep only Gemma's answer\n",
    "    rewritten = full_text[len(prompt):].strip()\n",
    "    if not rewritten:\n",
    "        rewritten = full_text.strip()\n",
    "\n",
    "    return rewritten\n",
    "\n",
    "# Quick example (fill in real values before running)\n",
    "# sample_image = \"img/example.png\"\n",
    "# sample_text = \"mississippi wind chime\"\n",
    "# print(\"Rewritten:\", rewrite_meme_with_gemma(sample_image, sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c4cf5",
   "metadata": {},
   "source": [
    "## 8. Run over a CSV of memes\n",
    "\n",
    "Assumes a CSV like:\n",
    "\n",
    "id,image_path,text  \n",
    "1,img/42953.png,\"its their character not their color that matters\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"memes.csv\"          # change to your path\n",
    "output_csv = \"memes_gemma2_blip.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "print(\"Loaded\", len(df), \"rows.\")\n",
    "\n",
    "rewrites = []\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = row[\"image_path\"]\n",
    "    text = row[\"text\"]\n",
    "    print(f\"[Row {idx}] {image_path}\")\n",
    "    try:\n",
    "        new_text = rewrite_meme_with_gemma(image_path, text)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        new_text = \"\"\n",
    "    rewrites.append(new_text)\n",
    "\n",
    "df[\"gemma2_blip_rewrite\"] = rewrites\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(\"Saved rewritten memes to\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
